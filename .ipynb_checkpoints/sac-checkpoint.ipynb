{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from collections import deque\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.distributions import Normal\n",
    "import torch.nn as nn\n",
    "import math\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer:\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.buffer = []\n",
    "        self.position = 0\n",
    "    \n",
    "    def push(self, state, action, reward, next_state, done):\n",
    "        if len(self.buffer) < self.capacity:\n",
    "            self.buffer.append(None)\n",
    "        self.buffer[self.position] = (state, action, reward, next_state, done)\n",
    "        self.position = (self.position + 1) % self.capacity\n",
    "    \n",
    "    def sample(self, batch_size):\n",
    "        batch = random.sample(self.buffer, batch_size)\n",
    "        state, action, reward, next_state, done = map(np.stack, zip(*batch))\n",
    "        return state, action, reward, next_state, done\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG_SIG_MAX = 2\n",
    "LOG_SIG_MIN = -20\n",
    "EPSILON = 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init_(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        torch.nn.init.xavier_uniform_(m.weight, gain=1)\n",
    "        torch.nn.init.constant_(m.bias, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ValueNetwork(nn.Module):\n",
    "    def __init__(self, state_dim, hidden_dim):\n",
    "        super(ValueNetwork, self).__init__()\n",
    "        \n",
    "        self.linear1 = nn.Linear(state_dim, hidden_dim)\n",
    "        self.linear2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.linear3 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.linear4 = nn.Linear(hidden_dim, 1)\n",
    "        \n",
    "        self.apply(weights_init_)\n",
    "        \n",
    "    def forward(self, state):\n",
    "        x = F.relu(self.linear1(state))\n",
    "        x = F.relu(self.linear2(x))\n",
    "        x = F.relu(self.linear3(x))\n",
    "        x = self.linear4(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QNetwork(nn.Module):\n",
    "    def __init__(self, num_inputs, num_actions, hidden_size, init_w=3e-3):\n",
    "        super(SoftQNetwork, self).__init__()\n",
    "        \n",
    "        # Q1\n",
    "        self.linear1_q1 = nn.Linear(num_inputs + num_actions, hidden_size)\n",
    "        self.linear2_q1 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.linear3_q1 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.linear4_q1 = nn.Linear(hidden_size, 1)\n",
    "        \n",
    "        # Q1\n",
    "        self.linear1_q2 = nn.Linear(num_inputs + num_actions, hidden_size)\n",
    "        self.linear2_q2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.linear3_q2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.linear4_q2 = nn.Linear(hidden_size, 1)\n",
    "        \n",
    "        self.apply(weights_init_)\n",
    "        \n",
    "    def forward(self, state, action):\n",
    "        x_state_action = torch.cat([state, action], 1)\n",
    "        \n",
    "        x1 = F.relu(self.linear1_q1(x_state_action))\n",
    "        x1 = F.relu(self.linear2_q1(x1))\n",
    "        x1 = F.relu(self.linear3_q1(x1))\n",
    "        x1 = self.linear4(x1)\n",
    "        \n",
    "        x2 = F.relu(self.linear1_q2(x_state_action))\n",
    "        x2 = F.relu(self.linear2_q2(x2))\n",
    "        x2 = F.relu(self.linear3_q2(x2))\n",
    "        x2 = self.linear4(x2)\n",
    "        \n",
    "        return x1, x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear1.weight tensor([[-0.4039,  0.0567,  0.4509, -0.0458],\n",
      "        [ 0.1921, -0.6469,  0.5294,  0.2056],\n",
      "        [-0.5741, -0.5269,  0.5190,  0.2072],\n",
      "        [ 0.4458, -0.4891, -0.4066, -0.3442]])\n",
      "linear1.bias tensor([0., 0., 0., 0.])\n",
      "linear2.weight tensor([[-0.8503, -0.6781, -0.2077,  0.5219],\n",
      "        [ 0.7573,  0.7078,  0.6030,  0.5681],\n",
      "        [-0.7756, -0.3552,  0.1104,  0.1408],\n",
      "        [ 0.0894, -0.7623, -0.2496,  0.1368]])\n",
      "linear2.bias tensor([0., 0., 0., 0.])\n",
      "linear3.weight tensor([[-0.1031, -0.6663,  0.5182,  0.2299],\n",
      "        [-0.3999,  0.8554, -0.0243,  0.7566],\n",
      "        [-0.7987,  0.5930,  0.7130, -0.2767],\n",
      "        [ 0.0521,  0.2824,  0.3026,  0.5067]])\n",
      "linear3.bias tensor([0., 0., 0., 0.])\n",
      "linear4.weight tensor([[ 0.3170,  0.9309, -0.0888, -0.1267]])\n",
      "linear4.bias tensor([0.])\n"
     ]
    }
   ],
   "source": [
    "for name, param in v.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print name, param.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
